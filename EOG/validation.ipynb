{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação dos dados EOG\n",
    "\n",
    "Neste notebook está incluído os seguintes passos:\n",
    "- Aplicação de características;\n",
    "- Criação do vetor de características;\n",
    "- Normalização de dados;\n",
    "- Seleção de características;\n",
    "- Classificação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma característica é uma propriedade individual mensurável ou característica de um fenômeno que está sendo observado. Em nosso caso de EOG, uma característica pode ser extraída no domínio do tempo ou no domínio da frequência. As características a seguir foram retiradas do artigo *EMG Feature Extraction for Tolerance of White Gaussian Noise* \\[1\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio do tempo\n",
    "\n",
    "1. Willison Amplitude (WAMP)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N-1}f(|x_i - x_{i+1}|) $\n",
    "    \n",
    "    > $ f(x) = \\begin{cases} 1 & \\text{if } x \\gt threshold \\\\ 0 & \\text{otherwise} \\end{cases} $\n",
    "\n",
    "2. Variance of EMG (VAR)\n",
    "\n",
    "    > $ \\frac{1}{N-1}\\sum_{i=1}^{N}x_i^2 $\n",
    "\n",
    "3. Root Mean Square (RMS)\n",
    "\n",
    "    > $ \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}|x_i|^2} $\n",
    "\n",
    "4. Waveform Length (WL)\n",
    "    \n",
    "    > $ \\sum_{i=1}^{N-1}|x_{i+1} - x_i| $\n",
    "\n",
    "5. Zero Crossing (ZC)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N}sgn(x_i) $\n",
    "    \n",
    "    > $ sgn(x) = \\begin{cases} 1 & \\text{if } x_i * x_{i+1} \\leq 0 \\\\ 0 & \\text{otherwise} \\end{cases} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio da frequência\n",
    "\n",
    "1. Median Frequency (FMD)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}PSD_j $\n",
    "\n",
    "2. Mean Frequency (FMN)\n",
    "\n",
    "    > $\\sum_{j=1}^{M}f_j PSD_j / \\sum_{j=1}^{M}PSD_j$\n",
    "    \n",
    "    > $ f_j = j * SampleRate / 2 * M $\n",
    "\n",
    "3. Modified Median Frequency (MMDF)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}A_j $\n",
    "    \n",
    "    > $ A_j = Amplitude\\ do\\ espectro\\ j $\n",
    "\n",
    "4. Modified Frequency Mean (MMNF)\n",
    "\n",
    "    > $ \\sum_{j=1}^{M}f_jAj / \\sum_{j=1}^{M}Aj $\n",
    "\n",
    "\n",
    "\\[1\\] Phinyomark, Angkoon & Limsakul, Chusak & Phukpattaranont, P.. (2008). EMG Feature Extraction for Tolerance of White Gaussian Noise.\n",
    "[Disponível neste link](https://www.researchgate.net/publication/263765853_EMG_Feature_Extraction_for_Tolerance_of_White_Gaussian_Noise)\n",
    "\n",
    "**Tarefa 1**: Descrever as características de acordo com o artigo citado e outros disponíveis relacionados. O que está querendo \"ser visto\" em cada característica? Qual é o significado matemático de cada uma delas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando as características\n",
    "\n",
    "É necessário implementar as características, geralmente em formato de funções ou métodos, para que seja possível aplicar tais funções aos dados de entrada e obter as características resultantes. A seguir temos a implementação das características `VAR` & `RMS` (domínio do tempo) e `FDM` & `MMDF` (domínio da frequência)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "\n",
    "def wamp(time, threshold):\n",
    "    return np.sum(np.abs(np.diff(time)) > threshold, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape) - 1))\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "\n",
    "def func_j(w):\n",
    "    sample_rate = np.arange(1, w.shape[-1]+1) * 200\n",
    "    return sample_rate / 2 * w.shape[-1]\n",
    "\n",
    "def fmn(w):\n",
    "    return np.sum(func_j(w) * PSD(w)) / fmd(w)*2\n",
    "\n",
    "def mmnf(w):\n",
    "    return np.sum(func_j(w) * np.abs(w),  axis=-1) / mmdf(w)*2\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "\n",
    "def zc(x):\n",
    "    return np.count_nonzero(np.diff(np.sign(x), axis=-1) != 0, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa 2**: Implemente todas as características apresentadas neste tutorial em formato de funções. Sinta-se livre também para buscar e implementar características além das apresentadas, citando as fontes de tais características.\n",
    "\n",
    "\n",
    "#### Vetor de características\n",
    "\n",
    "Ao final da implementação e seleção das características, deve ser escolhida as características e então teremos um vetor com todas elas implementadas.\n",
    "\n",
    "O vetor de características estará organizado da seguinte forma (exemplo p/ VAR, RMS, RDM e MMDF):\n",
    "\n",
    "| ID sample | VAR1 | RMS1 | FMD1 | MMDF1 | VAR2 | RMS2 | FMD2 | MMDF2 | Classe |\n",
    "|:---------:|:----:|:----:|:----:|:-----:|------|------|------|-------|:------:|\n",
    "|     1     |  v1  |  v1  |  v1  |   v1  | v1   | v1   | v1   | v1    |    0   |\n",
    "|     2     |  v2  |  v2  |  v2  |   v2  | v2   | v2   | v2   | v2    |    0   |\n",
    "|    ...    |  ... |  ... |  ... |  ...  | ...  | ...  | ...  | ...   |   ...  |\n",
    "|     N     |  vN  |  vN  |  vN  |   vN  | vN   | vN   | vN   | vN    |    7   |\n",
    "\n",
    "#### Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores orginais: (2, 28, 33, 2, 64) (2, 28, 33, 2, 33)\n",
      "(28, 33, 2) (28, 33, 2) (28, 33, 2) (28, 33, 2) (28, 33, 2) (28, 33, 2) (28, 33, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((28, 33, 2), (28, 33, 2), (28, 33, 2), (28, 33, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando dados do \"prepare.ipynb\"\n",
    "\n",
    "time_all = np.load(\"./datasets/all_time.npy\")\n",
    "freq_all = np.load(\"./datasets/all_freq.npy\")\n",
    "\n",
    "\n",
    "time = np.load(\"./datasets/gabi_time.npy\")\n",
    "freq = np.load(\"./datasets/gabi_freq.npy\")\n",
    "\n",
    "\n",
    "print(\"Shape dos vetores orginais:\", time_all.shape, freq_all.shape)\n",
    "\n",
    "# aplicando características\n",
    "\n",
    "data_var = var(time)\n",
    "data_rms = rms(time)\n",
    "data_wl = wl(time)\n",
    "data_wamp = wamp(time, np.median(time))\n",
    "\n",
    "data_fmd = fmd(freq)\n",
    "data_mmdf = mmdf(freq)\n",
    "data_fmn = fmn(freq)\n",
    "data_mmnf = mmnf(freq)\n",
    "\n",
    "print(data_wamp.shape, data_var.shape, data_rms.shape, data_fmd.shape, data_mmdf.shape, data_fmn.shape, data_mmnf.shape)\n",
    "\n",
    "data_zc = zc(freq)\n",
    "\n",
    "\n",
    "data_var.shape, data_rms.shape, data_fmd.shape, data_mmdf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todos os individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_all (7, 2, 28, 33, 2)\n",
      "features_all (2, 33, 28, 7, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1848, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial\n",
    "features_all = np.array([\n",
    "    wamp(time_all, np.median(time_all)),\n",
    "    var(time_all), \n",
    "    rms(time_all), \n",
    "    fmd(freq_all), \n",
    "    fmn(freq_all), \n",
    "    mmdf(freq_all), \n",
    "    mmnf(freq_all)\n",
    "])\n",
    "\n",
    "print(\"features_all\", features_all.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features_all = features_all.transpose(1, 3, 2, 0, 4)\n",
    "print(\"features_all\", features_all.shape)\n",
    "\n",
    "# criar vetor de características definitivo\n",
    "feature_reshaped = features_all.reshape(features_all.shape[0],  features_all.shape[1] * features_all.shape[2],  features_all.shape[3] * features_all.shape[4])\n",
    "feature_reshaped = feature_reshaped.reshape(feature_reshaped.shape[0] * feature_reshaped.shape[1], feature_reshaped.shape[2])\n",
    "feature_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Um individuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 28, 33, 2)\n",
      "(33, 28, 8, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.30000000e+01, 6.10000000e+01, 2.53104358e+00, ...,\n",
       "        1.03867318e+02, 2.30000000e+01, 2.20000000e+01],\n",
       "       [6.00000000e+01, 6.00000000e+01, 1.96654127e-01, ...,\n",
       "        5.43770605e+01, 2.20000000e+01, 2.50000000e+01],\n",
       "       [6.30000000e+01, 5.90000000e+01, 8.55192178e-02, ...,\n",
       "        5.30235871e+01, 2.20000000e+01, 2.30000000e+01],\n",
       "       ...,\n",
       "       [6.00000000e+01, 6.10000000e+01, 4.93594076e-02, ...,\n",
       "        4.01008363e+01, 1.80000000e+01, 1.60000000e+01],\n",
       "       [5.90000000e+01, 5.90000000e+01, 3.29442022e-03, ...,\n",
       "        5.67646923e+01, 1.50000000e+01, 1.60000000e+01],\n",
       "       [6.30000000e+01, 6.00000000e+01, 7.61725897e-01, ...,\n",
       "        5.68544603e+01, 1.20000000e+01, 1.40000000e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1 INDIVIDUO\n",
    "\n",
    "# União do vetor de características inicial\n",
    "features = np.array([data_wamp, data_var, data_rms, data_fmd, data_mmdf, data_fmn, data_wl, data_zc])\n",
    "print(features.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features = features.transpose(2, 1, 0, 3)\n",
    "print(features.shape)\n",
    "\n",
    "# # criar vetor de características definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1], features.shape[2] * features.shape[3])\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 3*: Realização da normalização dos dados utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_X = StandardScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 4*: Realização da seleção de características, utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do vetor de *labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_num 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "print('labels_num', len(labels_num))\n",
    "\n",
    "# criação do vetor de labels final\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)), axis=-1)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino\t-------\t (739, 1)\n",
      "Teste\t-------\t (185, 1) \n",
      "\n",
      "Acurácia > 0.25405405405405407 \n",
      "\n",
      "Treino\t-------\t (739, 2)\n",
      "Teste\t-------\t (185, 2) \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb Célula 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m param_grid \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m1000\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m]},\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m100\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.001\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpoly\u001b[39m\u001b[39m'\u001b[39m]},\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(svm\u001b[39m.\u001b[39mSVC(), param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Predição\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m y_pred \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    251\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/svm/_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    315\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    317\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    319\u001b[0m (\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[1;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[1;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[0;32m--> 329\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    330\u001b[0m     X,\n\u001b[1;32m    331\u001b[0m     y,\n\u001b[1;32m    332\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[1;32m    333\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    334\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    335\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[1;32m    336\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    337\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m    338\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[1;32m    339\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[1;32m    340\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[1;32m    341\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[1;32m    342\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    343\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[1;32m    344\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[1;32m    345\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    346\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    347\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    348\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[1;32m    349\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, f_classif\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE, f_classif\n",
    "\n",
    "max_k = ss_X.shape[1]\n",
    "\n",
    "for k in range(1, max_k + 1):\n",
    "    X_new_ss = SelectKBest(f_classif, k=k).fit_transform(ss_X, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_new_ss, y, test_size=0.2, random_state=42)\n",
    "    print('Treino\\t-------\\t', x_train.shape)\n",
    "    print('Teste\\t-------\\t', x_test.shape, \"\\n\")\n",
    "\n",
    "    param_grid = [\n",
    "        {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "        {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf', 'poly']},\n",
    "    ]\n",
    "\n",
    "    grid = GridSearchCV(svm.SVC(), param_grid, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    # Predição\n",
    "    y_pred = grid.predict(x_test)\n",
    "    print('Acurácia >', metrics.accuracy_score(y_test, y_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 5*: Realização da classificação utilizando `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "# código"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
