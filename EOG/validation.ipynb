{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação dos dados EOG\n",
    "\n",
    "Neste notebook está incluído os seguintes passos:\n",
    "- Aplicação de características;\n",
    "- Criação do vetor de características;\n",
    "- Normalização de dados;\n",
    "- Seleção de características;\n",
    "- Classificação dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma característica é uma propriedade individual mensurável ou característica de um fenômeno que está sendo observado. Em nosso caso de EOG, uma característica pode ser extraída no domínio do tempo ou no domínio da frequência. As características a seguir foram retiradas do artigo *EMG Feature Extraction for Tolerance of White Gaussian Noise* \\[1\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio do tempo\n",
    "\n",
    "1. Willison Amplitude (WAMP)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N-1}f(|x_i - x_{i+1}|) $\n",
    "    \n",
    "    > $ f(x) = \\begin{cases} 1 & \\text{if } x \\gt threshold \\\\ 0 & \\text{otherwise} \\end{cases} $\n",
    "\n",
    "2. Variance of EMG (VAR)\n",
    "\n",
    "    > $ \\frac{1}{N-1}\\sum_{i=1}^{N}x_i^2 $\n",
    "\n",
    "3. Root Mean Square (RMS)\n",
    "\n",
    "    > $ \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}|x_i|^2} $\n",
    "\n",
    "4. Waveform Length (WL)\n",
    "    \n",
    "    > $ \\sum_{i=1}^{N-1}|x_{i+1} - x_i| $\n",
    "\n",
    "5. Zero Crossing (ZC)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N}sgn(x_i) $\n",
    "    \n",
    "    > $ sgn(x) = \\begin{cases} 1 & \\text{if } x_i * x_{i+1} \\leq 0 \\\\ 0 & \\text{otherwise} \\end{cases} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio da frequência\n",
    "\n",
    "1. Median Frequency (FMD)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}PSD_j $\n",
    "\n",
    "2. Mean Frequency (FMN)\n",
    "\n",
    "    > $\\sum_{j=1}^{M}f_j PSD_j / \\sum_{j=1}^{M}PSD_j$\n",
    "    \n",
    "    > $ f_j = j * SampleRate / 2 * M $\n",
    "\n",
    "3. Modified Median Frequency (MMDF)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}A_j $\n",
    "    \n",
    "    > $ A_j = Amplitude\\ do\\ espectro\\ j $\n",
    "\n",
    "4. Modified Frequency Mean (MMNF)\n",
    "\n",
    "    > $ \\sum_{j=1}^{M}f_jAj / \\sum_{j=1}^{M}Aj $\n",
    "\n",
    "\n",
    "\\[1\\] Phinyomark, Angkoon & Limsakul, Chusak & Phukpattaranont, P.. (2008). EMG Feature Extraction for Tolerance of White Gaussian Noise.\n",
    "[Disponível neste link](https://www.researchgate.net/publication/263765853_EMG_Feature_Extraction_for_Tolerance_of_White_Gaussian_Noise)\n",
    "\n",
    "**Tarefa 1**: Descrever as características de acordo com o artigo citado e outros disponíveis relacionados. O que está querendo \"ser visto\" em cada característica? Qual é o significado matemático de cada uma delas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando as características\n",
    "\n",
    "É necessário implementar as características, geralmente em formato de funções ou métodos, para que seja possível aplicar tais funções aos dados de entrada e obter as características resultantes. A seguir temos a implementação das características `VAR` & `RMS` (domínio do tempo) e `FDM` & `MMDF` (domínio da frequência)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape) - 1))\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa 2**: Implemente todas as características apresentadas neste tutorial em formato de funções. Sinta-se livre também para buscar e implementar características além das apresentadas, citando as fontes de tais características.\n",
    "\n",
    "\n",
    "#### Vetor de características\n",
    "\n",
    "Ao final da implementação e seleção das características, deve ser escolhida as características e então teremos um vetor com todas elas implementadas.\n",
    "\n",
    "O vetor de características estará organizado da seguinte forma (exemplo p/ VAR, RMS, RDM e MMDF):\n",
    "\n",
    "| ID sample | VAR1 | RMS1 | FMD1 | MMDF1 | VAR2 | RMS2 | FMD2 | MMDF2 | Classe |\n",
    "|:---------:|:----:|:----:|:----:|:-----:|------|------|------|-------|:------:|\n",
    "|     1     |  v1  |  v1  |  v1  |   v1  | v1   | v1   | v1   | v1    |    0   |\n",
    "|     2     |  v2  |  v2  |  v2  |   v2  | v2   | v2   | v2   | v2    |    0   |\n",
    "|    ...    |  ... |  ... |  ... |  ...  | ...  | ...  | ...  | ...   |   ...  |\n",
    "|     N     |  vN  |  vN  |  vN  |   vN  | vN   | vN   | vN   | vN    |    7   |\n",
    "\n",
    "#### Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores orginais: (28, 2, 33, 64) (28, 33, 2, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((28, 33, 2), (28, 33, 2), (28, 33, 2), (28, 33, 2))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando dados do \"prepare.ipynb\"\n",
    "\n",
    "time_all = np.load(\"./datasets/all_time.npy\")\n",
    "freq_all = np.load(\"./datasets/all_freq.npy\")\n",
    "\n",
    "# print(\"time_all\", time_all.shape, freq_all.shape)\n",
    "\n",
    "time = np.load(\"./datasets/gabi_time.npy\")\n",
    "freq = np.load(\"./datasets/gabi_freq.npy\")\n",
    "\n",
    "print(\"Shape dos vetores orginais:\", x.shape, w.shape)\n",
    "\n",
    "# aplicando características\n",
    "\n",
    "data_var = var(time)\n",
    "data_rms = rms(time)\n",
    "\n",
    "data_fmd = fmd(freq)\n",
    "data_mmdf = mmdf(freq)\n",
    "\n",
    "data_var.shape, data_rms.shape, data_fmd.shape, data_mmdf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todos os individuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_all (4, 2, 28, 33, 2)\n",
      "features_all (2, 33, 28, 4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 924, 8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial\n",
    "features_all = np.array([var(time_all), rms(time_all), fmd(freq_all), mmdf(freq_all)])\n",
    "\n",
    "print(\"features_all\", features_all.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features_all = features_all.transpose(1, 3, 2, 0, 4)\n",
    "print(\"features_all\", features_all.shape)\n",
    "\n",
    "# criar vetor de características definitivo\n",
    "feature_reshaped = features_all.reshape(features_all.shape[0],  features_all.shape[1] * features_all.shape[2],  features_all.shape[3] * features_all.shape[4])\n",
    "feature_reshaped = feature_reshaped.reshape(feature_reshaped.shape[0] * feature_reshaped.shape[1], feature_reshaped.shape[2])\n",
    "feature_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Um individuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 33, 2)\n",
      "(33, 28, 4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, 8)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1 INDIVIDUO\n",
    "\n",
    "# União do vetor de características inicial\n",
    "features = np.array([data_var, data_rms, data_fmd, data_mmdf])\n",
    "print(features.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features = features.transpose(2, 1, 0, 3)\n",
    "print(features.shape)\n",
    "\n",
    "# # criar vetor de características definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1], features.shape[2] * features.shape[3])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 3*: Realização da normalização dos dados utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aplicando normalização\n",
    "# X = StandardScaler().fit_transform(features_all)\n",
    "\n",
    "# # código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 4*: Realização da seleção de características, utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do vetor de *labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_num 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "print('labels_num', len(labels_num))\n",
    "\n",
    "# criação do vetor de labels final\n",
    "y = np.array(labels_num * int(features.shape[0] / len(labels_num)))\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 8) (924,)\n",
      "[0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0\n",
      " 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0\n",
      " 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2\n",
      " 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1\n",
      " 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1\n",
      " 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0\n",
      " 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3\n",
      " 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2\n",
      " 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2\n",
      " 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3\n",
      " 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3\n",
      " 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1\n",
      " 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2\n",
      " 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2\n",
      " 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0\n",
      " 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3\n",
      " 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1\n",
      " 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1\n",
      " 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2\n",
      " 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0\n",
      " 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3\n",
      " 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1\n",
      " 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0\n",
      " 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1\n",
      " 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3] (924, 7)\n",
      "[0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0\n",
      " 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0\n",
      " 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2\n",
      " 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1\n",
      " 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1\n",
      " 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0\n",
      " 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3\n",
      " 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2\n",
      " 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2\n",
      " 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3\n",
      " 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3\n",
      " 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1\n",
      " 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2\n",
      " 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2\n",
      " 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0\n",
      " 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3\n",
      " 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1\n",
      " 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1\n",
      " 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2\n",
      " 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0\n",
      " 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3\n",
      " 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1\n",
      " 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0\n",
      " 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1\n",
      " 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3] (924, 6)\n",
      "[0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0\n",
      " 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0\n",
      " 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2\n",
      " 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1\n",
      " 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1\n",
      " 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0\n",
      " 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3\n",
      " 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2\n",
      " 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2\n",
      " 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3\n",
      " 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3\n",
      " 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1\n",
      " 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2\n",
      " 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2\n",
      " 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0\n",
      " 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3\n",
      " 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1\n",
      " 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1\n",
      " 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2\n",
      " 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0\n",
      " 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3\n",
      " 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1\n",
      " 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0\n",
      " 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1\n",
      " 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3] (924, 4)\n",
      "[0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0\n",
      " 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0\n",
      " 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2\n",
      " 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1\n",
      " 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1\n",
      " 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0\n",
      " 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3\n",
      " 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2\n",
      " 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2\n",
      " 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3\n",
      " 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3\n",
      " 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1\n",
      " 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2\n",
      " 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2\n",
      " 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0\n",
      " 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3\n",
      " 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1\n",
      " 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1\n",
      " 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2\n",
      " 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0\n",
      " 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3\n",
      " 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1\n",
      " 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0\n",
      " 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1\n",
      " 3 1 0 1 2 0 2 3 0 1 2 3 2 3 3 1 0 3 0 0 1 2 3 2 1 0 2 1 3 1 0 1 2 0 2 3] (924, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/feature_selection/_base.py:102: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'k' parameter of SelectKBest must be a str among {'all'} or an int in the range [0, inf). Got -8 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb Célula 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(aux_features\u001b[39m.\u001b[39mshape, y\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m ks:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     X_new \u001b[39m=\u001b[39m SelectKBest(f_classif, k\u001b[39m=\u001b[39;49minitial_k \u001b[39m-\u001b[39;49m k)\u001b[39m.\u001b[39;49mfit_transform(aux_features, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(y, X_new\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/EOG/validation.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# código    \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/base.py:919\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[1;32m   1141\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1142\u001b[0m )\n\u001b[1;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1145\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[1;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/base.py:638\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    631\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \n\u001b[1;32m    633\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    639\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[1;32m    640\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    641\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[1;32m    642\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'k' parameter of SelectKBest must be a str among {'all'} or an int in the range [0, inf). Got -8 instead."
     ]
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, f_classif\n",
    "\n",
    "num_of_chars = features.shape[1]\n",
    "ks = [2**i for i in range(0, 12)]\n",
    "initial_k = num_of_chars\n",
    "accs = []\n",
    "\n",
    "aux_features = np.abs(features)\n",
    "print(aux_features.shape, y.shape)\n",
    "for k in ks:\n",
    "    X_new = SelectKBest(f_classif, k=initial_k - k).fit_transform(aux_features, y)\n",
    "    print(y, X_new.shape)\n",
    "# código    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 5*: Realização da classificação utilizando `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "# código"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
