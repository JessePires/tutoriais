{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import mne\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise  da base de dados `Beta` utilizando algoritmos de ML\n",
    "\n",
    "Neste notebook será analisado o `Beta dataset` utilizando algoritmos de ML para realizar a (1) extração de características. (2) seleção de características e (3) classificação dos dados.\n",
    "\n",
    "### Pontos Importantes do Dataset\n",
    " \n",
    "- Frequências estimuladas (total de 40, com a diferença de 0.2 Hz uma da outra): 8.0, 8.2, ..., 15.6, 15.8;\n",
    "- Taxa de amostragem: 250 Hz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisar os \"momentos\" em que ocorrem evocação do sinal SSVEP\n",
    "\n",
    "1. Criar o objeto `MNE` a partir dos dados do participante.\n",
    "2. Aplicar no objeto `MNE` o filtro passa-faixa nos valores de 6 - 18 Hz.\n",
    "3. Criar cópias do objeto `MNE` com fatias de tempo menores para analisar momentos que ocorrem estimulos ou não (verificar artigo).\n",
    "   - **a)** 0.0 - 0.5 segundos e  2.5 - 3.0 segundos ocorre apenas ruído;\n",
    "   - **b**) 0.5 - 2.5 segundos ocorre sinal SSVEP (com ruídos)\n",
    "4. Com os sinais separados em objetos MNE, aplicar a `FFT`, para que seja possível plotar gráficos que contenham (ou não) as informações. \n",
    "   - Os dados devem ser plotados no dominio da frequência (após a transformada de Fourier). O FFT pode ser realizada pela biblioteca `scipy.fft`.\n",
    "   - Deve ser observado que as janelas (a) com ruídos não aparecerão de fato o sinal SSVEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 750)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"../../datasets/beta/data.npy\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 64\n",
    "sfreq = 250\n",
    "ch_names = list(np.load(\"../../datasets/beta/channels.npy\"))\n",
    "ch_types = ['eeg'] * len(ch_names)\n",
    "info = mne.create_info(ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "best = ['P6', 'PO3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load(\"../../datasets/beta/labels.npy\")\n",
    "unique_labels = sorted(set(labels))\n",
    "event_dict = {str(value): index  for index, value in enumerate(unique_labels)}\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "160 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Setting up band-pass filter from 6 - 18 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 6.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Upper passband edge: 18.00 Hz\n",
      "- Upper transition bandwidth: 4.50 Hz (-6 dB cutoff frequency: 20.25 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 4607 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 5201 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 5831 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 6497 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 7937 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 8711 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 9521 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>10.0: 4<br/>10.2: 4<br/>10.4: 4<br/>10.6: 4<br/>10.8: 4<br/>11.0: 4<br/>11.2: 4<br/>11.4: 4<br/>11.6: 4<br/>11.8: 4<br/>12.0: 4<br/>12.2: 4<br/>12.4: 4<br/>12.600000000000001: 4<br/>12.8: 4<br/>13.0: 4<br/>13.200000000000001: 4<br/>13.4: 4<br/>13.600000000000001: 4<br/>13.8: 4<br/>14.0: 4<br/>14.200000000000001: 4<br/>14.4: 4<br/>14.600000000000001: 4<br/>14.8: 4<br/>15.0: 4<br/>15.200000000000001: 4<br/>15.4: 4<br/>15.600000000000001: 4<br/>15.8: 4<br/>8.0: 4<br/>8.2: 4<br/>8.4: 4<br/>8.6: 4<br/>8.799999999999999: 4<br/>9.0: 4<br/>9.2: 4<br/>9.4: 4<br/>9.6: 4<br/>9.8: 4</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 2.996 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray |  160 events (all good), 0 – 2.996 s, baseline off, ~58.7 MB, data loaded,\n",
       " '8.0': 4\n",
       " '8.2': 4\n",
       " '8.4': 4\n",
       " '8.6': 4\n",
       " '8.799999999999999': 4\n",
       " '9.0': 4\n",
       " '9.2': 4\n",
       " '9.4': 4\n",
       " '9.6': 4\n",
       " '9.8': 4\n",
       " and 30 more events ...>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# método para transformar labels categóricos\n",
    "le = LabelEncoder()\n",
    "events = np.column_stack((\n",
    "    np.array(range(len(labels))),\n",
    "    np.zeros(160, dtype=int),\n",
    "    le.fit_transform(labels))\n",
    ")\n",
    "\n",
    "# print(events.shape)\n",
    "\n",
    "mne_data = mne.EpochsArray(data, info, events, event_id=event_dict)\n",
    "filtered_mne_data = mne_data.filter(6, 18)\n",
    "\n",
    "filtered_mne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5514/3614421376.py:3: RuntimeWarning: tmax is not in time interval. tmax is set to <class 'mne.epochs.EpochsArray'>.tmax (2.996 s)\n",
      "  end_noise = filtered_mne_data.copy().crop(tmin=2.5, tmax=3.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5896.0918793349665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_noise = filtered_mne_data.copy().crop(tmin=0.0, tmax=0.5)\n",
    "middle = filtered_mne_data.copy().crop(tmin=0.5, tmax=2.5)\n",
    "end_noise = filtered_mne_data.copy().crop(tmin=2.5, tmax=3.0)\n",
    "\n",
    "noise_power = []\n",
    "\n",
    "fft_start_result = np.fft.fft(start_noise)\n",
    "fft_end_result = np.fft.fft(end_noise)\n",
    "\n",
    "# densidade espectral de potência (PSD)\n",
    "psd_start = np.abs(fft_start_result) ** 2\n",
    "psd_end = np.abs(fft_end_result) ** 2\n",
    "\n",
    "# média da potência nos intervalos de tempo sem estímulo\n",
    "base_power = np.mean(psd_start, axis=-1)\n",
    "rest_power = np.mean(psd_end, axis=-1)\n",
    "\n",
    "# média das duas médias de potência obtidas anteriorment\n",
    "mean_noise_power = np.mean([base_power + rest_power])\n",
    "\n",
    "mean_noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 250\n",
    "\n",
    "# frequências alvo\n",
    "target_frequencies = np.arange(8, 16, 0.2)\n",
    "\n",
    "# lista para armazenar as amplitudes nas frequências alvo\n",
    "target_amplitudes = []\n",
    "\n",
    "for channel_data in middle.get_data():\n",
    "    target = []\n",
    "    for electrode in channel_data:\n",
    "\n",
    "        fft_result = np.fft.fft(electrode)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "        frequencies = np.fft.fftfreq(len(fft_result), 1 / sr)\n",
    "        target_amplitudes_trial = []\n",
    "        for target_frequency in target_frequencies:\n",
    "            # encontrando o índice da frequência alvo no espectro de frequência\n",
    "            index = np.argmin(np.abs(frequencies - target_frequency))\n",
    "            # amplitude na frequência alvo\n",
    "            amplitude = np.sqrt(psd[index])\n",
    "            target_amplitudes_trial.append(amplitude)\n",
    "\n",
    "        target.append(target_amplitudes_trial)\n",
    "\n",
    "\n",
    "    target_amplitudes.append(target)\n",
    "\n",
    "target_amplitudes = np.array(target_amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 40)\n",
      "(160, 64, 120)\n"
     ]
    }
   ],
   "source": [
    "# forçando (estragando) valor de \"estimated_background_noise\" para não sobrar valores negativos\n",
    "target_amplitudes_adjusted = np.abs(target_amplitudes - mean_noise_power)\n",
    "\n",
    "# subtraindo o ruído de fundo das amplitudes\n",
    "narrow_band_SNR = 10 * np.log10(target_amplitudes_adjusted / mean_noise_power)\n",
    "\n",
    "total_power = np.sum(target_amplitudes_adjusted)\n",
    "wide_band_SNR = 10 * np.log10(target_amplitudes_adjusted / total_power)\n",
    "\n",
    "print(target_amplitudes_adjusted.shape)\n",
    "\n",
    "data = np.array([target_amplitudes_adjusted, narrow_band_SNR, wide_band_SNR])\n",
    "data = data.swapaxes(0, 1)\n",
    "data = data.swapaxes(1, 2)\n",
    "data = data.reshape(data.shape[0], data.shape[1], data.shape[2] * data.shape[3])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira alternativa (remoção manual de características)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (160, 64, 120)\n",
      "After (160, 9, 120)\n",
      "Labels (160,)\n"
     ]
    }
   ],
   "source": [
    "# Removendo eletrodos não listados\n",
    "\n",
    "ch_names = np.load(\"../../datasets/beta/channels.npy\")\n",
    "\n",
    "channels_to_keep = ['PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'POZ', 'O1', 'OZ', 'O2']\n",
    "indexes_to_remove = np.where(np.isin(ch_names, channels_to_keep, invert=True))\n",
    "\n",
    "print(\"Before\", data.shape)\n",
    "data_filtered = np.delete(data, indexes_to_remove, axis=1)\n",
    "print(\"After\", data_filtered.shape)\n",
    "print(\"Labels\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 1080)\n"
     ]
    }
   ],
   "source": [
    "data_filtered_reshape = data_filtered.reshape(data_filtered.shape[0], data_filtered.shape[1] * data_filtered.shape[2])\n",
    "print(data_filtered_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.25\n",
      "f1_score 0.2284722222222222\n"
     ]
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(data_filtered_reshape)\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda alternativa (utilizando remoção automático de características RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 7680)\n"
     ]
    }
   ],
   "source": [
    "# reorganizando os dados\n",
    "\n",
    "X_reshape_auto = data.reshape(data.shape[0], data.shape[1] * data.shape[2])\n",
    "print(X_reshape_auto.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 501)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160, 64, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionando mais características\n",
    "\n",
    "middle = filtered_mne_data.copy().crop(tmin=0.5, tmax=2.5)\n",
    "print(middle.get_data().shape)\n",
    "\n",
    "fft_middle_result = np.fft.fft(middle)\n",
    "\n",
    "# densidade espectral de potência (PSD)\n",
    "psd_middle = np.abs(fft_middle_result) ** 2\n",
    "\n",
    "# média da potência nos intervalos de tempo sem estímulo\n",
    "middle_power = np.mean(psd_middle, axis=-1)\n",
    "\n",
    "sr = 250\n",
    "\n",
    "# frequências alvo\n",
    "target_frequencies = np.arange(8, 16, 0.2)\n",
    "\n",
    "# lista para armazenar as amplitudes nas frequências alvo\n",
    "target_amplitudes = []\n",
    "\n",
    "for channel_data in middle.get_data():\n",
    "    target = []\n",
    "    for electrode in channel_data:\n",
    "\n",
    "        fft_result = np.fft.fft(electrode)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "        frequencies = np.fft.fftfreq(len(fft_result), 1 / sr)\n",
    "        target_amplitudes_trial = []\n",
    "\n",
    "        for target_frequency in target_frequencies:\n",
    "            # encontrando o índice da frequência alvo no espectro de frequência\n",
    "            index = np.argmin(np.abs(frequencies - target_frequency))\n",
    "            # amplitude na frequência alvo\n",
    "            amplitude = np.sqrt(psd[index])\n",
    "            target_amplitudes_trial.append(amplitude)\n",
    "\n",
    "        target.append(target_amplitudes_trial)\n",
    "\n",
    "\n",
    "    target_amplitudes.append(target)\n",
    "\n",
    "target_amplitudes = np.array(target_amplitudes)\n",
    "target_amplitudes.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jesse/UTFPR/RECONHECIMENTO_DE_PADROES/tutoriais/SSVEP/src/beta/beta_ml.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jesse/UTFPR/RECONHECIMENTO_DE_PADROES/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_reshape_auto \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39mfit_transform(X_reshape_auto)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jesse/UTFPR/RECONHECIMENTO_DE_PADROES/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m rfe \u001b[39m=\u001b[39m RFECV(SVC(kernel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m), step\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m, min_features_to_select\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jesse/UTFPR/RECONHECIMENTO_DE_PADROES/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_final \u001b[39m=\u001b[39m rfe\u001b[39m.\u001b[39;49mfit_transform(X_reshape_auto, y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jesse/UTFPR/RECONHECIMENTO_DE_PADROES/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(X_final\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:726\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    723\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    724\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m--> 726\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    727\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[1;32m    728\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    729\u001b[0m )\n\u001b[1;32m    731\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[1;32m    732\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:727\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    723\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    724\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m    726\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m--> 727\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[1;32m    728\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    729\u001b[0m )\n\u001b[1;32m    731\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[1;32m    732\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:32\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     30\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[1;32m     31\u001b[0m X_test, y_test \u001b[39m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m rfe\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m     33\u001b[0m     X_train,\n\u001b[1;32m     34\u001b[0m     y_train,\n\u001b[1;32m     35\u001b[0m     \u001b[39mlambda\u001b[39;49;00m estimator, features: _score(\n\u001b[1;32m     36\u001b[0m         estimator, X_test[:, features], y_test, scorer\n\u001b[1;32m     37\u001b[0m     ),\n\u001b[1;32m     38\u001b[0m )\u001b[39m.\u001b[39mscores_\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py:297\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting estimator with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m features.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m np\u001b[39m.\u001b[39msum(support_))\n\u001b[0;32m--> 297\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X[:, features], y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    299\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m    300\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    301\u001b[0m     estimator,\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimportance_getter,\n\u001b[1;32m    303\u001b[0m     transform_func\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    251\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/sklearn/svm/_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    315\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    317\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    319\u001b[0m (\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[1;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[1;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[0;32m--> 329\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    330\u001b[0m     X,\n\u001b[1;32m    331\u001b[0m     y,\n\u001b[1;32m    332\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[1;32m    333\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    334\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    335\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[1;32m    336\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    337\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m    338\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[1;32m    339\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[1;32m    340\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[1;32m    341\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[1;32m    342\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    343\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[1;32m    344\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[1;32m    345\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    346\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    347\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    348\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[1;32m    349\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X_reshape_auto = StandardScaler().fit_transform(X_reshape_auto)\n",
    "\n",
    "rfe = RFECV(SVC(kernel=\"linear\"), step=0.0001, min_features_to_select=1, cv=3)\n",
    "X_final = rfe.fit_transform(X_reshape_auto, y)\n",
    "\n",
    "print(X_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4583333333333333\n",
      "f1_score 0.40972222222222227\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 7680)\n"
     ]
    }
   ],
   "source": [
    "# reorganizando os dados\n",
    "\n",
    "X_reshape_auto = data.reshape(data.shape[0], data.shape[1] * data.shape[2])\n",
    "print(X_reshape_auto.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 501)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160, 64, 40)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionando mais características\n",
    "\n",
    "middle = filtered_mne_data.copy().crop(tmin=0.5, tmax=2.5)\n",
    "print(middle.get_data().shape)\n",
    "\n",
    "fft_middle_result = np.fft.fft(middle)\n",
    "\n",
    "# densidade espectral de potência (PSD)\n",
    "psd_middle = np.abs(fft_middle_result) ** 2\n",
    "\n",
    "# média da potência nos intervalos de tempo sem estímulo\n",
    "middle_power = np.mean(psd_middle, axis=-1)\n",
    "\n",
    "sr = 250\n",
    "\n",
    "# frequências alvo\n",
    "target_frequencies = np.arange(8, 16, 0.2)\n",
    "\n",
    "# lista para armazenar as amplitudes nas frequências alvo\n",
    "target_amplitudes = []\n",
    "\n",
    "for channel_data in middle.get_data():\n",
    "    target = []\n",
    "    for electrode in channel_data:\n",
    "\n",
    "        fft_result = np.fft.fft(electrode)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "        frequencies = np.fft.fftfreq(len(fft_result), 1 / sr)\n",
    "        target_amplitudes_trial = []\n",
    "\n",
    "        for target_frequency in target_frequencies:\n",
    "            # encontrando o índice da frequência alvo no espectro de frequência\n",
    "            index = np.argmin(np.abs(frequencies - target_frequency))\n",
    "            # amplitude na frequência alvo\n",
    "            amplitude = np.sqrt(psd[index])\n",
    "            target_amplitudes_trial.append(amplitude)\n",
    "\n",
    "        target.append(target_amplitudes_trial)\n",
    "\n",
    "\n",
    "    target_amplitudes.append(target)\n",
    "\n",
    "target_amplitudes = np.array(target_amplitudes)\n",
    "target_amplitudes.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 1066)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_reshape_auto = StandardScaler().fit_transform(X_reshape_auto)\n",
    "\n",
    "rfe = RFECV(SVC(kernel=\"linear\"), step=0.0001, min_features_to_select=1, cv=3)\n",
    "X_final = rfe.fit_transform(X_reshape_auto, y)\n",
    "\n",
    "print(X_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5\n",
      "f1_score 0.49999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "svm = GridSearchCV(SVC(), param_grid={'C' : [1, 10, 100, 1000], 'kernel': ['linear']}, cv=StratifiedKFold(n_splits=3, shuffle=True), n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "/home/jhonatancunha/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13194444444444445\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "num_of_chars = X_reshape_auto.shape[1]\n",
    "\n",
    "# <!-- usar o k best \n",
    "\n",
    "# usar o k inicial como metade\n",
    "# e ir reduzindo na potencia de 2\n",
    "\n",
    "# 512\n",
    "# 256\n",
    "# 128\n",
    "# ...\n",
    "# 2\n",
    "#  -->\n",
    "\n",
    "ks = [2**i for i in range(0, 12)]\n",
    "initial_k = num_of_chars\n",
    "accs = []\n",
    "\n",
    "for k in ks:\n",
    "    X_new = SelectKBest(f_classif, k=initial_k - k).fit_transform(X_reshape_auto, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y, shuffle=True, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # unique, counts = np.unique(y_train, return_counts=True)\n",
    "    # print(np.asarray((unique, counts)).T)\n",
    "\n",
    "    parameters = {'C':[1, 10, 100, 1000], 'kernel': ['linear']}\n",
    "    svm = GridSearchCV(SVC(), cv=4, param_grid=parameters, scoring=\"accuracy\")\n",
    "    svm.fit(X_train, y_train.ravel())\n",
    "    predicts = svm.predict(X_test)\n",
    "    accs.append(accuracy_score(predicts, y_test))\n",
    "\n",
    "\n",
    "print(np.average(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extração de características\n",
    "\n",
    "Uma característica importante de acordo com o artigo base do dataset `BETA` é o *signal-to-noise ratio* (SNR).\n",
    "\n",
    "Ao final desta etapa, será obtido um vetor de características. Estas podem ser:\n",
    "- `SNR` (obrigatória);\n",
    "- Maior valor espectral (FFT);\n",
    "- Médio dos valores espectrais (FFT);\n",
    "\n",
    "\n",
    "Dimensionalidade dos dados será explicada da seguinte forma:\n",
    "\n",
    "`40, 4, 64, 750` -> 40 targets, 4 trials, 64 channels e 750 values.\n",
    "\n",
    "`160, 64 (SRN) + 64 (MÉDIA) + 64 (MAIOR) ...`\n",
    "\n",
    "Resultando em  `160, 192`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleção de características e classsificação\n",
    "\n",
    "Como existem diversos eletrodos (canais) que não obtem sinal SSVEP, podemos extrair as características que não contribuem para a classificação dos dados.\n",
    "\n",
    "\n",
    "Podemos utilizar o método `RFE` (*Recursive Feature Elimination*) aplicador por meio de `sklearn.feature_selection.RFE`, aprimorand o parâmetro `n_features_to_select` até obter o melhor resultado de classificação.\n",
    "\n",
    "Para a classificação propriamente dita, é considerado o uso do método `SVM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to calculate SNR https://saturncloud.io/blog/calculating-signaltonoise-ratio-in-python-with-scipy-v11/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutoriais--u7LmRJB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
