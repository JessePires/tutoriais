{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mne\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise  da base de dados `Beta` utilizando algoritmos de ML\n",
    "\n",
    "Neste notebook será analisado o `Beta dataset` utilizando algoritmos de ML para realizar a (1) extração de características. (2) seleção de características e (3) classificação dos dados.\n",
    "\n",
    "### Pontos Importantes do Dataset\n",
    " \n",
    "- Frequências estimuladas (total de 40, com a diferença de 0.2 Hz uma da outra): 8.0, 8.2, ..., 15.6, 15.8;\n",
    "- Taxa de amostragem: 250 Hz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisar os \"momentos\" em que ocorrem evocação do sinal SSVEP\n",
    "\n",
    "1. Criar o objeto `MNE` a partir dos dados do participante.\n",
    "2. Aplicar no objeto `MNE` o filtro passa-faixa nos valores de 6 - 18 Hz.\n",
    "3. Criar cópias do objeto `MNE` com fatias de tempo menores para analisar momentos que ocorrem estimulos ou não (verificar artigo).\n",
    "   - **a)** 0.0 - 0.5 segundos e  2.5 - 3.0 segundos ocorre apenas ruído;\n",
    "   - **b**) 0.5 - 2.5 segundos ocorre sinal SSVEP (com ruídos)\n",
    "4. Com os sinais separados em objetos MNE, aplicar a `FFT`, para que seja possível plotar gráficos que contenham (ou não) as informações. \n",
    "   - Os dados devem ser plotados no dominio da frequência (após a transformada de Fourier). O FFT pode ser realizada pela biblioteca `scipy.fft`.\n",
    "   - Deve ser observado que as janelas (a) com ruídos não aparecerão de fato o sinal SSVEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 750)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"../../datasets/beta/data.npy\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 64\n",
    "sfreq = 250\n",
    "ch_names = list(np.load(\"../../datasets/beta/channels.npy\"))\n",
    "ch_types = ['eeg'] * len(ch_names)\n",
    "info = mne.create_info(ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "best = ['P6', 'PO3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load(\"../../datasets/beta/labels.npy\")\n",
    "unique_labels = sorted(set(labels))\n",
    "event_dict = {str(value): index  for index, value in enumerate(unique_labels)}\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "160 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Setting up band-pass filter from 6 - 18 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 6.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Upper passband edge: 18.00 Hz\n",
      "- Upper transition bandwidth: 4.50 Hz (-6 dB cutoff frequency: 20.25 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 4607 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 5201 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 5831 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 6497 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 7937 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 8711 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 9521 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>10.0: 4<br/>10.2: 4<br/>10.4: 4<br/>10.6: 4<br/>10.8: 4<br/>11.0: 4<br/>11.2: 4<br/>11.4: 4<br/>11.6: 4<br/>11.8: 4<br/>12.0: 4<br/>12.2: 4<br/>12.4: 4<br/>12.600000000000001: 4<br/>12.8: 4<br/>13.0: 4<br/>13.200000000000001: 4<br/>13.4: 4<br/>13.600000000000001: 4<br/>13.8: 4<br/>14.0: 4<br/>14.200000000000001: 4<br/>14.4: 4<br/>14.600000000000001: 4<br/>14.8: 4<br/>15.0: 4<br/>15.200000000000001: 4<br/>15.4: 4<br/>15.600000000000001: 4<br/>15.8: 4<br/>8.0: 4<br/>8.2: 4<br/>8.4: 4<br/>8.6: 4<br/>8.799999999999999: 4<br/>9.0: 4<br/>9.2: 4<br/>9.4: 4<br/>9.6: 4<br/>9.8: 4</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 2.996 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray |  160 events (all good), 0 – 2.996 s, baseline off, ~58.7 MB, data loaded,\n",
       " '8.0': 4\n",
       " '8.2': 4\n",
       " '8.4': 4\n",
       " '8.6': 4\n",
       " '8.799999999999999': 4\n",
       " '9.0': 4\n",
       " '9.2': 4\n",
       " '9.4': 4\n",
       " '9.6': 4\n",
       " '9.8': 4\n",
       " and 30 more events ...>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# método para transformar labels categóricos\n",
    "le = LabelEncoder()\n",
    "events = np.column_stack((\n",
    "    np.array(range(len(labels))),\n",
    "    np.zeros(160, dtype=int),\n",
    "    le.fit_transform(labels))\n",
    ")\n",
    "\n",
    "# print(events.shape)\n",
    "\n",
    "mne_data = mne.EpochsArray(data, info, events, event_id=event_dict)\n",
    "filtered_mne_data = mne_data.filter(6, 18)\n",
    "\n",
    "filtered_mne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7720/3614421376.py:3: RuntimeWarning: tmax is not in time interval. tmax is set to <class 'mne.epochs.EpochsArray'>.tmax (2.996 s)\n",
      "  end_noise = filtered_mne_data.copy().crop(tmin=2.5, tmax=3.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5896.091879334966"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_noise = filtered_mne_data.copy().crop(tmin=0.0, tmax=0.5)\n",
    "middle = filtered_mne_data.copy().crop(tmin=0.5, tmax=2.5)\n",
    "end_noise = filtered_mne_data.copy().crop(tmin=2.5, tmax=3.0)\n",
    "\n",
    "noise_power = []\n",
    "\n",
    "fft_start_result = np.fft.fft(start_noise)\n",
    "fft_end_result = np.fft.fft(end_noise)\n",
    "\n",
    "# densidade espectral de potência (PSD)\n",
    "psd_start = np.abs(fft_start_result) ** 2\n",
    "psd_end = np.abs(fft_end_result) ** 2\n",
    "\n",
    "# média da potência nos intervalos de tempo sem estímulo\n",
    "base_power = np.mean(psd_start, axis=-1)\n",
    "rest_power = np.mean(psd_end, axis=-1)\n",
    "\n",
    "# média das duas médias de potência obtidas anteriorment\n",
    "mean_noise_power = np.mean([base_power + rest_power])\n",
    "\n",
    "mean_noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 250\n",
    "\n",
    "# frequências alvo\n",
    "target_frequencies = np.arange(8, 16, 0.2)\n",
    "# lista para armazenar as amplitudes nas frequências alvo\n",
    "target_amplitudes = []\n",
    "\n",
    "for channel_data in middle.get_data():\n",
    "    target = []\n",
    "    for electrode in channel_data:\n",
    "\n",
    "        fft_result = np.fft.fft(electrode)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "        frequencies = np.fft.fftfreq(len(fft_result), 1 / sr)\n",
    "        target_amplitudes_trial = []\n",
    "        for target_frequency in target_frequencies:\n",
    "            # encontrando o índice da frequência alvo no espectro de frequência\n",
    "            index = np.argmin(np.abs(frequencies - target_frequency))\n",
    "            # amplitude na frequência alvo\n",
    "            amplitude = np.sqrt(psd[index])\n",
    "            target_amplitudes_trial.append(amplitude)\n",
    "\n",
    "        target.append(target_amplitudes_trial)\n",
    "\n",
    "\n",
    "    target_amplitudes.append(target)\n",
    "\n",
    "target_amplitudes = np.array(target_amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 40)\n",
      "(160, 64, 120)\n"
     ]
    }
   ],
   "source": [
    "# forçando (estragando) valor de \"estimated_background_noise\" para não sobrar valores negativos\n",
    "target_amplitudes_adjusted = np.abs(target_amplitudes - mean_noise_power)\n",
    "\n",
    "# subtraindo o ruído de fundo das amplitudes\n",
    "narrow_band_SNR = 10 * np.log10(target_amplitudes_adjusted / mean_noise_power)\n",
    "\n",
    "total_power = np.sum(target_amplitudes_adjusted)\n",
    "wide_band_SNR = 10 * np.log10(target_amplitudes_adjusted / total_power)\n",
    "\n",
    "print(target_amplitudes_adjusted.shape)\n",
    "\n",
    "data = np.array([target_amplitudes_adjusted, narrow_band_SNR, wide_band_SNR])\n",
    "data = data.swapaxes(0, 1)\n",
    "data = data.swapaxes(1, 2)\n",
    "data = data.reshape(data.shape[0], data.shape[1], data.shape[2] * data.shape[3])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira alternativa (remoção manual de características)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (160, 64, 120)\n",
      "After (160, 9, 120)\n",
      "Labels (160,)\n"
     ]
    }
   ],
   "source": [
    "# Removendo eletrodos não listados\n",
    "\n",
    "ch_names = np.load(\"../../datasets/beta/channels.npy\")\n",
    "\n",
    "channels_to_keep = ['PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'POZ', 'O1', 'OZ', 'O2']\n",
    "indexes_to_remove = np.where(np.isin(ch_names, channels_to_keep, invert=True))\n",
    "\n",
    "print(\"Before\", data.shape)\n",
    "data_filtered = np.delete(data, indexes_to_remove, axis=1)\n",
    "print(\"After\", data_filtered.shape)\n",
    "print(\"Labels\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 1080)\n"
     ]
    }
   ],
   "source": [
    "data_filtered_reshape = data_filtered.reshape(data_filtered.shape[0], data_filtered.shape[1] * data_filtered.shape[2])\n",
    "print(data_filtered_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.25\n",
      "f1_score 0.2284722222222222\n"
     ]
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(data_filtered_reshape)\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda alternativa (utilizando remoção automático de características RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 7680)\n"
     ]
    }
   ],
   "source": [
    "# reorganizando os dados\n",
    "\n",
    "X_reshape_auto = data.reshape(data.shape[0], data.shape[1] * data.shape[2])\n",
    "print(X_reshape_auto.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/SSVEP/src/beta/beta_ml.ipynb Célula 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_reshape_auto \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39mfit_transform(X_reshape_auto)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m rfe \u001b[39m=\u001b[39m RFECV(SVC(kernel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m), step\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m, min_features_to_select\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_final \u001b[39m=\u001b[39m rfe\u001b[39m.\u001b[39;49mfit_transform(X_reshape_auto, y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jhonatancunha/UTFPR/8Periodo/padroes/tutoriais/SSVEP/src/beta/beta_ml.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(X_final\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:726\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    723\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    724\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m--> 726\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    727\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[1;32m    728\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    729\u001b[0m )\n\u001b[1;32m    731\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[1;32m    732\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:727\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    723\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    724\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m    726\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m--> 727\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[1;32m    728\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    729\u001b[0m )\n\u001b[1;32m    731\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[1;32m    732\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:32\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     30\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[1;32m     31\u001b[0m X_test, y_test \u001b[39m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m rfe\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m     33\u001b[0m     X_train,\n\u001b[1;32m     34\u001b[0m     y_train,\n\u001b[1;32m     35\u001b[0m     \u001b[39mlambda\u001b[39;49;00m estimator, features: _score(\n\u001b[1;32m     36\u001b[0m         estimator, X_test[:, features], y_test, scorer\n\u001b[1;32m     37\u001b[0m     ),\n\u001b[1;32m     38\u001b[0m )\u001b[39m.\u001b[39mscores_\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:300\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    297\u001b[0m estimator\u001b[39m.\u001b[39mfit(X[:, features], y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    299\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    301\u001b[0m     estimator,\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimportance_getter,\n\u001b[1;32m    303\u001b[0m     transform_func\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msquare\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    305\u001b[0m ranks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(importances)\n\u001b[1;32m    307\u001b[0m \u001b[39m# for sparse case ranks is matrix\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/feature_selection/_base.py:209\u001b[0m, in \u001b[0;36m_get_feature_importances\u001b[0;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(getter, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m getter \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 209\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mcoef_\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m    210\u001b[0m             getter \u001b[39m=\u001b[39m attrgetter(\u001b[39m\"\u001b[39m\u001b[39mcoef_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m         \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfeature_importances_\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/svm/_base.py:658\u001b[0m, in \u001b[0;36mBaseLibSVM.coef_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    656\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcoef_ is only available when using a linear kernel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 658\u001b[0m coef \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_coef()\n\u001b[1;32m    660\u001b[0m \u001b[39m# coef_ being a read-only property, it's better to mark the value as\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# immutable to avoid hiding potential bugs for the unsuspecting user.\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(coef):\n\u001b[1;32m    663\u001b[0m     \u001b[39m# sparse matrix do not have global flags\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/sklearn/svm/_base.py:976\u001b[0m, in \u001b[0;36mBaseSVC._get_coef\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m         coef \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mvstack(coef)\u001b[39m.\u001b[39mtocsr()\n\u001b[1;32m    975\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 976\u001b[0m         coef \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack(coef)\n\u001b[1;32m    978\u001b[0m \u001b[39mreturn\u001b[39;00m coef\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/tutoriais--u7LmRJB/lib/python3.8/site-packages/numpy/core/shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 296\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_reshape_auto = StandardScaler().fit_transform(X_reshape_auto)\n",
    "\n",
    "rfe = RFECV(SVC(kernel=\"linear\"), step=0.0001, min_features_to_select=1, cv=3)\n",
    "X_final = rfe.fit_transform(X_reshape_auto, y)\n",
    "print(X_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4583333333333333\n",
      "f1_score 0.40972222222222227\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extração de características\n",
    "\n",
    "Uma característica importante de acordo com o artigo base do dataset `BETA` é o *signal-to-noise ratio* (SNR).\n",
    "\n",
    "Ao final desta etapa, será obtido um vetor de características. Estas podem ser:\n",
    "- `SNR` (obrigatória);\n",
    "- Maior valor espectral (FFT);\n",
    "- Médio dos valores espectrais (FFT);\n",
    "\n",
    "\n",
    "Dimensionalidade dos dados será explicada da seguinte forma:\n",
    "\n",
    "`40, 4, 64, 750` -> 40 targets, 4 trials, 64 channels e 750 values.\n",
    "\n",
    "`160, 64 (SRN) + 64 (MÉDIA) + 64 (MAIOR) ...`\n",
    "\n",
    "Resultando em  `160, 192`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleção de características e classsificação\n",
    "\n",
    "Como existem diversos eletrodos (canais) que não obtem sinal SSVEP, podemos extrair as características que não contribuem para a classificação dos dados.\n",
    "\n",
    "\n",
    "Podemos utilizar o método `RFE` (*Recursive Feature Elimination*) aplicador por meio de `sklearn.feature_selection.RFE`, aprimorand o parâmetro `n_features_to_select` até obter o melhor resultado de classificação.\n",
    "\n",
    "Para a classificação propriamente dita, é considerado o uso do método `SVM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to calculate SNR https://saturncloud.io/blog/calculating-signaltonoise-ratio-in-python-with-scipy-v11/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutoriais--u7LmRJB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
